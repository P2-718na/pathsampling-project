{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run from bootstrap paths\n",
    "\n",
    "Now we will use the initial trajectories we obtained from bootstrapping to run an MSTIS simulation. This will show both how objects can be regenerated from storage and how regenerated equivalent objects can be used in place of objects that weren't stored.\n",
    "\n",
    "Tasks covered in this notebook:\n",
    "* Loading OPS objects from storage\n",
    "* Ways of assigning initial trajectories to initial samples\n",
    "* Setting up a path sampling simulation with various move schemes\n",
    "* Visualizing trajectories while the path sampling is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:22:36.791627Z",
     "start_time": "2024-02-14T14:22:36.787029Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:30:40.241275Z",
     "start_time": "2024-02-14T14:29:45.130242Z"
    }
   },
   "outputs": [],
   "source": [
    "import openpathsampling as paths\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# the openpathsampling OpenMM engine\n",
    "import openpathsampling.engines.openmm as eng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading things from storage\n",
    "\n",
    "First we'll reload some of the stuff we stored before. Of course, this starts with opening the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:31:03.853799Z",
     "start_time": "2024-02-14T14:30:40.242568Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning on use of the timeseries module: If the inherent timescales of the system are long compared to those being analyzed, this statistical inefficiency may be an underestimate.  The estimate presumes the use of many statistically independent samples.  Tests should be performed to assess whether this condition is satisfied.   Be cautious in the interpretation of the data.\n",
      "\n",
      "********* JAX NOT FOUND *********\n",
      " PyMBAR can run faster with JAX  \n",
      " But will work fine without it   \n",
      "Either install with pip or conda:\n",
      "      pip install pybar[jax]     \n",
      "               OR                \n",
      "      conda install pymbar       \n",
      "*********************************\n"
     ]
    }
   ],
   "source": [
    "old_store = paths.AnalysisStorage(\"ala_mstis_bootstrap.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of information can be recovered from the old storage, and so we don't have the recreate it. However, we did not save our network, so we'll have to create a new one. Since the network creates the ensembles, that means we will have to translate the trajectories from the old ensembles to new ensembles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:31:10.266049Z",
     "start_time": "2024-02-14T14:31:10.237478Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PathMovers: 45\n",
      "Engines: 3\n",
      "Samples: 538\n",
      "Trajectories: 509\n",
      "Ensembles: 315\n",
      "SampleSets: 502\n",
      "Snapshots: 40242\n",
      "Networks: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"PathMovers:\", len(old_store.pathmovers))\n",
    "print(\"Engines:\", len(old_store.engines))\n",
    "print(\"Samples:\", len(old_store.samples))\n",
    "print(\"Trajectories:\", len(old_store.trajectories))\n",
    "print(\"Ensembles:\", len(old_store.ensembles))\n",
    "print(\"SampleSets:\", len(old_store.samplesets))\n",
    "print(\"Snapshots:\", len(old_store.snapshots))\n",
    "print(\"Networks:\", len(old_store.networks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading from storage is very easy. Each store is a list. We take the 0th snapshot as a template (it doesn't actually matter which one) for the next storage we'll create. There's only one engine stored, so we take the only one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:31:11.916961Z",
     "start_time": "2024-02-14T14:31:11.870519Z"
    }
   },
   "outputs": [],
   "source": [
    "# template = old_store.snapshots[0]\n",
    "engine = old_store.engines['default']\n",
    "mstis = old_store.networks[0]\n",
    "sset = old_store.tag['sampleset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### initialize engine\n",
    "if we do not select a platform the fastest possible will be chosen but we explicitly request to use the one in the config file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Reference', 'CPU', 'CUDA']\n"
     ]
    }
   ],
   "source": [
    "print(engine.available_platforms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:31:12.813540Z",
     "start_time": "2024-02-14T14:31:12.742150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engine uses platform `CUDA`\n"
     ]
    }
   ],
   "source": [
    "platform = 'CUDA' #CUDA\n",
    "engine.initialize(platform)\n",
    "\n",
    "print('Engine uses platform `%s`' % engine.platform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:31:14.016093Z",
     "start_time": "2024-02-14T14:31:13.508155Z"
    }
   },
   "outputs": [],
   "source": [
    "sset.sanity_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running RETIS\n",
    "\n",
    "Now we run the full calculation. Up to here, we haven't been storing any of our results. This time, we'll start a storage object, and we'll save the network we've created. Then we'll run a new `PathSampling` calculation object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:31:14.718938Z",
     "start_time": "2024-02-14T14:31:14.697868Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'storage' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# logging creates ops_output.log file with details of what the calculation is doing\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#import logging.config\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m#logging.config.fileConfig(\"logging.conf\", disable_existing_loggers=False)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mstorage\u001b[49m\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'storage' is not defined"
     ]
    }
   ],
   "source": [
    "# logging creates ops_output.log file with details of what the calculation is doing\n",
    "#import logging.config\n",
    "#logging.config.fileConfig(\"logging.conf\", disable_existing_loggers=False)\n",
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:31:15.066098Z",
     "start_time": "2024-02-14T14:31:14.884600Z"
    }
   },
   "outputs": [],
   "source": [
    "storage = paths.storage.Storage(\"ala_mstis_production.nc\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:31:15.970290Z",
     "start_time": "2024-02-14T14:31:15.599586Z"
    }
   },
   "outputs": [],
   "source": [
    "storage.snapshots.save(old_store.snapshots[0]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can sample we still need to set the actual `MoveScheme` which determines the\n",
    "set of moves to apply to our set of samples and effectively doing the steps in\n",
    "replica (sampleset) space. We pick the default scheme for mstis and feed it with\n",
    "the engine to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:31:16.650117Z",
     "start_time": "2024-02-14T14:31:16.637704Z"
    }
   },
   "outputs": [],
   "source": [
    "scheme = paths.DefaultScheme(mstis, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and finally generate the `PathSampler` object to conduct the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:32:14.448293Z",
     "start_time": "2024-02-14T14:31:17.550107Z"
    }
   },
   "outputs": [],
   "source": [
    "mstis_calc = paths.PathSampling(\n",
    "    storage=storage,\n",
    "    sample_set=sset,\n",
    "    move_scheme=scheme\n",
    ")\n",
    "#mstis_calc.save_frequency = 50\n",
    "mstis_calc.save_frequency = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now everything is ready: let's run the simulation! The first step takes a little since all\n",
    "necessary information, i.e. the engines, topologies, initial snapshots, ..., need to be\n",
    "stored. Then the monte carlo steps will be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on Monte Carlo cycle number 50000\n",
      "Running for 3 hours 14 minutes 44 seconds -  0.23 seconds per step\n",
      "Estimated time remaining: 0 seconds\n",
      "DONE! Completed 50000 Monte Carlo cycles.\n"
     ]
    }
   ],
   "source": [
    "#mstis_calc.run(10000)\n",
    "mstis_calc.run(50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:54:56.263999Z",
     "start_time": "2024-02-14T14:54:56.245226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50001\n"
     ]
    }
   ],
   "source": [
    "print(len(storage.steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-14T14:54:56.369467Z",
     "start_time": "2024-02-14T14:54:56.253599Z"
    }
   },
   "outputs": [],
   "source": [
    "# commented out during development, so we can \"run all\" and then do more\n",
    "storage.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
